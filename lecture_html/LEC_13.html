
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Lecture 13 Quiz</title>
</head>
<body>
  <h1>Lecture 13 - Quiz</h1>
  
<!-- Question 1 -->
<div class="question" id="q1">
  <h3>Question 1</h3>
  <p>What does perplexity measure in the context of a language model?</p>
  <div class="options">
    <label><input type="radio" name="q1" value="b"> B. The computational time needed for training.</label><br>
    <label><input type="radio" name="q1" value="a"> A. The length of the predicted sentence.</label><br>
    <label><input type="radio" name="q1" value="d"> D. The vocabulary size used by the model.</label><br>
    <label><input type="radio" name="q1" value="c"> C. How well the model predicts a sequence of text.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q1', 'c')">Submit</button>
  <div class="context" id="context-q1">
    <p>Perplexity is a measure of how surprised a model is by the next word. A lower perplexity indicates better performance.</p>
  </div>
</div>

<!-- Question 2 -->
<div class="question" id="q2">
  <h3>Question 2</h3>
  <p>In a unigram language model, what is being calculated?</p>
  <div class="options">
    <label><input type="radio" name="q2" value="c"> C. P(previous_word|word)</label><br>
    <label><input type="radio" name="q2" value="a"> A. P(word|previous_word)</label><br>
    <label><input type="radio" name="q2" value="b"> B. P(word)</label><br>
    <label><input type="radio" name="q2" value="d"> D. P(word1, word2)</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q2', 'b')">Submit</button>
  <div class="context" id="context-q2">
    <p>In a unigram language model, we calculate P(word), which is the probability of a word occurring independently of any context.</p>
  </div>
</div>

<!-- Question 3 -->
<div class="question" id="q3">
  <h3>Question 3</h3>
  <p>Which of the following best describes the relationship between entropy and perplexity in a language model?</p>
  <div class="options">
    <label><input type="radio" name="q3" value="c"> C. Perplexity is the exponentiation of entropy.</label><br>
    <label><input type="radio" name="q3" value="b"> B. Entropy is the square of perplexity.</label><br>
    <label><input type="radio" name="q3" value="d"> D. Entropy and perplexity are unrelated.</label><br>
    <label><input type="radio" name="q3" value="a"> A. Perplexity is the inverse of entropy.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q3', 'c')">Submit</button>
  <div class="context" id="context-q3">
    <p>Perplexity is calculated as 2 to the power of the entropy, measuring uncertainty in the prediction.</p>
  </div>
</div>

<!-- Question 4 -->
<div class="question" id="q4">
  <h3>Question 4</h3>
  <p>Which temperature setting is likely to produce the most deterministic output in a sampling-based text generator?</p>
  <div class="options">
    <label><input type="radio" name="q4" value="a"> A. 0.2</label><br>
    <label><input type="radio" name="q4" value="c"> C. 1.0</label><br>
    <label><input type="radio" name="q4" value="b"> B. 0.5</label><br>
    <label><input type="radio" name="q4" value="d"> D. 2.0</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q4', 'a')">Submit</button>
  <div class="context" id="context-q4">
    <p>Lower temperatures produce more deterministic outputs by making high-probability words even more likely.</p>
  </div>
</div>

<!-- Question 5 -->
<div class="question" id="q5">
  <h3>Question 5</h3>
  <p>In a unigram language model, what is being calculated?</p>
  <div class="options">
    <label><input type="radio" name="q5" value="a"> A. P(word|previous_word)</label><br>
    <label><input type="radio" name="q5" value="d"> D. P(word1, word2)</label><br>
    <label><input type="radio" name="q5" value="c"> C. P(previous_word|word)</label><br>
    <label><input type="radio" name="q5" value="b"> B. P(word)</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q5', 'b')">Submit</button>
  <div class="context" id="context-q5">
    <p>In a unigram language model, we calculate P(word), which is the probability of a word occurring independently of any context.</p>
  </div>
</div>

<!-- Question 6 -->
<div class="question" id="q6">
  <h3>Question 6</h3>
  <p>Why is a character-level RNN used for text generation tasks?</p>
  <div class="options">
    <label><input type="radio" name="q6" value="c"> C. It supports floating point arithmetic.</label><br>
    <label><input type="radio" name="q6" value="a"> A. It eliminates the need for a tokenizer.</label><br>
    <label><input type="radio" name="q6" value="b"> B. It guarantees faster computation.</label><br>
    <label><input type="radio" name="q6" value="d"> D. It requires less training data.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q6', 'a')">Submit</button>
  <div class="context" id="context-q6">
    <p>Character-level models can generate novel word sequences and donâ€™t rely on a tokenizer for word boundaries.</p>
  </div>
</div>

<!-- Question 7 -->
<div class="question" id="q7">
  <h3>Question 7</h3>
  <p>In a unigram language model, what is being calculated?</p>
  <div class="options">
    <label><input type="radio" name="q7" value="b"> B. P(word)</label><br>
    <label><input type="radio" name="q7" value="d"> D. P(word1, word2)</label><br>
    <label><input type="radio" name="q7" value="c"> C. P(previous_word|word)</label><br>
    <label><input type="radio" name="q7" value="a"> A. P(word|previous_word)</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q7', 'b')">Submit</button>
  <div class="context" id="context-q7">
    <p>In a unigram language model, we calculate P(word), which is the probability of a word occurring independently of any context.</p>
  </div>
</div>

<!-- Question 8 -->
<div class="question" id="q8">
  <h3>Question 8</h3>
  <p>In a unigram language model, what is being calculated?</p>
  <div class="options">
    <label><input type="radio" name="q8" value="a"> A. P(word|previous_word)</label><br>
    <label><input type="radio" name="q8" value="b"> B. P(word)</label><br>
    <label><input type="radio" name="q8" value="d"> D. P(word1, word2)</label><br>
    <label><input type="radio" name="q8" value="c"> C. P(previous_word|word)</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q8', 'b')">Submit</button>
  <div class="context" id="context-q8">
    <p>In a unigram language model, we calculate P(word), which is the probability of a word occurring independently of any context.</p>
  </div>
</div>

<!-- Question 9 -->
<div class="question" id="q9">
  <h3>Question 9</h3>
  <p>In a unigram language model, what is being calculated?</p>
  <div class="options">
    <label><input type="radio" name="q9" value="c"> C. P(previous_word|word)</label><br>
    <label><input type="radio" name="q9" value="b"> B. P(word)</label><br>
    <label><input type="radio" name="q9" value="a"> A. P(word|previous_word)</label><br>
    <label><input type="radio" name="q9" value="d"> D. P(word1, word2)</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q9', 'b')">Submit</button>
  <div class="context" id="context-q9">
    <p>In a unigram language model, we calculate P(word), which is the probability of a word occurring independently of any context.</p>
  </div>
</div>

<!-- Question 10 -->
<div class="question" id="q10">
  <h3>Question 10</h3>
  <p>Which of the following best describes the relationship between entropy and perplexity in a language model?</p>
  <div class="options">
    <label><input type="radio" name="q10" value="a"> A. Perplexity is the inverse of entropy.</label><br>
    <label><input type="radio" name="q10" value="b"> B. Entropy is the square of perplexity.</label><br>
    <label><input type="radio" name="q10" value="d"> D. Entropy and perplexity are unrelated.</label><br>
    <label><input type="radio" name="q10" value="c"> C. Perplexity is the exponentiation of entropy.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q10', 'c')">Submit</button>
  <div class="context" id="context-q10">
    <p>Perplexity is calculated as 2 to the power of the entropy, measuring uncertainty in the prediction.</p>
  </div>
</div>

<!-- Question 11 -->
<div class="question" id="q11">
  <h3>Question 11</h3>
  <p>What does perplexity measure in the context of a language model?</p>
  <div class="options">
    <label><input type="radio" name="q11" value="b"> B. The computational time needed for training.</label><br>
    <label><input type="radio" name="q11" value="c"> C. How well the model predicts a sequence of text.</label><br>
    <label><input type="radio" name="q11" value="a"> A. The length of the predicted sentence.</label><br>
    <label><input type="radio" name="q11" value="d"> D. The vocabulary size used by the model.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q11', 'c')">Submit</button>
  <div class="context" id="context-q11">
    <p>Perplexity is a measure of how surprised a model is by the next word. A lower perplexity indicates better performance.</p>
  </div>
</div>

<!-- Question 12 -->
<div class="question" id="q12">
  <h3>Question 12</h3>
  <p>What does perplexity measure in the context of a language model?</p>
  <div class="options">
    <label><input type="radio" name="q12" value="d"> D. The vocabulary size used by the model.</label><br>
    <label><input type="radio" name="q12" value="a"> A. The length of the predicted sentence.</label><br>
    <label><input type="radio" name="q12" value="b"> B. The computational time needed for training.</label><br>
    <label><input type="radio" name="q12" value="c"> C. How well the model predicts a sequence of text.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q12', 'c')">Submit</button>
  <div class="context" id="context-q12">
    <p>Perplexity is a measure of how surprised a model is by the next word. A lower perplexity indicates better performance.</p>
  </div>
</div>

<!-- Question 13 -->
<div class="question" id="q13">
  <h3>Question 13</h3>
  <p>Which temperature setting is likely to produce the most deterministic output in a sampling-based text generator?</p>
  <div class="options">
    <label><input type="radio" name="q13" value="a"> A. 0.2</label><br>
    <label><input type="radio" name="q13" value="c"> C. 1.0</label><br>
    <label><input type="radio" name="q13" value="d"> D. 2.0</label><br>
    <label><input type="radio" name="q13" value="b"> B. 0.5</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q13', 'a')">Submit</button>
  <div class="context" id="context-q13">
    <p>Lower temperatures produce more deterministic outputs by making high-probability words even more likely.</p>
  </div>
</div>

<!-- Question 14 -->
<div class="question" id="q14">
  <h3>Question 14</h3>
  <p>What does perplexity measure in the context of a language model?</p>
  <div class="options">
    <label><input type="radio" name="q14" value="b"> B. The computational time needed for training.</label><br>
    <label><input type="radio" name="q14" value="c"> C. How well the model predicts a sequence of text.</label><br>
    <label><input type="radio" name="q14" value="a"> A. The length of the predicted sentence.</label><br>
    <label><input type="radio" name="q14" value="d"> D. The vocabulary size used by the model.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q14', 'c')">Submit</button>
  <div class="context" id="context-q14">
    <p>Perplexity is a measure of how surprised a model is by the next word. A lower perplexity indicates better performance.</p>
  </div>
</div>

<!-- Question 15 -->
<div class="question" id="q15">
  <h3>Question 15</h3>
  <p>In a unigram language model, what is being calculated?</p>
  <div class="options">
    <label><input type="radio" name="q15" value="a"> A. P(word|previous_word)</label><br>
    <label><input type="radio" name="q15" value="c"> C. P(previous_word|word)</label><br>
    <label><input type="radio" name="q15" value="b"> B. P(word)</label><br>
    <label><input type="radio" name="q15" value="d"> D. P(word1, word2)</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q15', 'b')">Submit</button>
  <div class="context" id="context-q15">
    <p>In a unigram language model, we calculate P(word), which is the probability of a word occurring independently of any context.</p>
  </div>
</div>

<!-- Question 16 -->
<div class="question" id="q16">
  <h3>Question 16</h3>
  <p>Why is a character-level RNN used for text generation tasks?</p>
  <div class="options">
    <label><input type="radio" name="q16" value="b"> B. It guarantees faster computation.</label><br>
    <label><input type="radio" name="q16" value="c"> C. It supports floating point arithmetic.</label><br>
    <label><input type="radio" name="q16" value="a"> A. It eliminates the need for a tokenizer.</label><br>
    <label><input type="radio" name="q16" value="d"> D. It requires less training data.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q16', 'a')">Submit</button>
  <div class="context" id="context-q16">
    <p>Character-level models can generate novel word sequences and donâ€™t rely on a tokenizer for word boundaries.</p>
  </div>
</div>

<!-- Question 17 -->
<div class="question" id="q17">
  <h3>Question 17</h3>
  <p>What does perplexity measure in the context of a language model?</p>
  <div class="options">
    <label><input type="radio" name="q17" value="b"> B. The computational time needed for training.</label><br>
    <label><input type="radio" name="q17" value="c"> C. How well the model predicts a sequence of text.</label><br>
    <label><input type="radio" name="q17" value="a"> A. The length of the predicted sentence.</label><br>
    <label><input type="radio" name="q17" value="d"> D. The vocabulary size used by the model.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q17', 'c')">Submit</button>
  <div class="context" id="context-q17">
    <p>Perplexity is a measure of how surprised a model is by the next word. A lower perplexity indicates better performance.</p>
  </div>
</div>

<!-- Question 18 -->
<div class="question" id="q18">
  <h3>Question 18</h3>
  <p>Which of the following best describes the relationship between entropy and perplexity in a language model?</p>
  <div class="options">
    <label><input type="radio" name="q18" value="c"> C. Perplexity is the exponentiation of entropy.</label><br>
    <label><input type="radio" name="q18" value="d"> D. Entropy and perplexity are unrelated.</label><br>
    <label><input type="radio" name="q18" value="a"> A. Perplexity is the inverse of entropy.</label><br>
    <label><input type="radio" name="q18" value="b"> B. Entropy is the square of perplexity.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q18', 'c')">Submit</button>
  <div class="context" id="context-q18">
    <p>Perplexity is calculated as 2 to the power of the entropy, measuring uncertainty in the prediction.</p>
  </div>
</div>

<!-- Question 19 -->
<div class="question" id="q19">
  <h3>Question 19</h3>
  <p>Why is a character-level RNN used for text generation tasks?</p>
  <div class="options">
    <label><input type="radio" name="q19" value="c"> C. It supports floating point arithmetic.</label><br>
    <label><input type="radio" name="q19" value="d"> D. It requires less training data.</label><br>
    <label><input type="radio" name="q19" value="a"> A. It eliminates the need for a tokenizer.</label><br>
    <label><input type="radio" name="q19" value="b"> B. It guarantees faster computation.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q19', 'a')">Submit</button>
  <div class="context" id="context-q19">
    <p>Character-level models can generate novel word sequences and donâ€™t rely on a tokenizer for word boundaries.</p>
  </div>
</div>

<!-- Question 20 -->
<div class="question" id="q20">
  <h3>Question 20</h3>
  <p>What does perplexity measure in the context of a language model?</p>
  <div class="options">
    <label><input type="radio" name="q20" value="b"> B. The computational time needed for training.</label><br>
    <label><input type="radio" name="q20" value="a"> A. The length of the predicted sentence.</label><br>
    <label><input type="radio" name="q20" value="d"> D. The vocabulary size used by the model.</label><br>
    <label><input type="radio" name="q20" value="c"> C. How well the model predicts a sequence of text.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q20', 'c')">Submit</button>
  <div class="context" id="context-q20">
    <p>Perplexity is a measure of how surprised a model is by the next word. A lower perplexity indicates better performance.</p>
  </div>
</div>

<!-- Question 21 -->
<div class="question" id="q21">
  <h3>Question 21</h3>
  <p>Which of the following best describes the relationship between entropy and perplexity in a language model?</p>
  <div class="options">
    <label><input type="radio" name="q21" value="c"> C. Perplexity is the exponentiation of entropy.</label><br>
    <label><input type="radio" name="q21" value="a"> A. Perplexity is the inverse of entropy.</label><br>
    <label><input type="radio" name="q21" value="b"> B. Entropy is the square of perplexity.</label><br>
    <label><input type="radio" name="q21" value="d"> D. Entropy and perplexity are unrelated.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q21', 'c')">Submit</button>
  <div class="context" id="context-q21">
    <p>Perplexity is calculated as 2 to the power of the entropy, measuring uncertainty in the prediction.</p>
  </div>
</div>

<!-- Question 22 -->
<div class="question" id="q22">
  <h3>Question 22</h3>
  <p>Why is a character-level RNN used for text generation tasks?</p>
  <div class="options">
    <label><input type="radio" name="q22" value="d"> D. It requires less training data.</label><br>
    <label><input type="radio" name="q22" value="c"> C. It supports floating point arithmetic.</label><br>
    <label><input type="radio" name="q22" value="b"> B. It guarantees faster computation.</label><br>
    <label><input type="radio" name="q22" value="a"> A. It eliminates the need for a tokenizer.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q22', 'a')">Submit</button>
  <div class="context" id="context-q22">
    <p>Character-level models can generate novel word sequences and donâ€™t rely on a tokenizer for word boundaries.</p>
  </div>
</div>

<!-- Question 23 -->
<div class="question" id="q23">
  <h3>Question 23</h3>
  <p>Which of the following best describes the relationship between entropy and perplexity in a language model?</p>
  <div class="options">
    <label><input type="radio" name="q23" value="c"> C. Perplexity is the exponentiation of entropy.</label><br>
    <label><input type="radio" name="q23" value="d"> D. Entropy and perplexity are unrelated.</label><br>
    <label><input type="radio" name="q23" value="b"> B. Entropy is the square of perplexity.</label><br>
    <label><input type="radio" name="q23" value="a"> A. Perplexity is the inverse of entropy.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q23', 'c')">Submit</button>
  <div class="context" id="context-q23">
    <p>Perplexity is calculated as 2 to the power of the entropy, measuring uncertainty in the prediction.</p>
  </div>
</div>

<!-- Question 24 -->
<div class="question" id="q24">
  <h3>Question 24</h3>
  <p>Why is a character-level RNN used for text generation tasks?</p>
  <div class="options">
    <label><input type="radio" name="q24" value="a"> A. It eliminates the need for a tokenizer.</label><br>
    <label><input type="radio" name="q24" value="d"> D. It requires less training data.</label><br>
    <label><input type="radio" name="q24" value="b"> B. It guarantees faster computation.</label><br>
    <label><input type="radio" name="q24" value="c"> C. It supports floating point arithmetic.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q24', 'a')">Submit</button>
  <div class="context" id="context-q24">
    <p>Character-level models can generate novel word sequences and donâ€™t rely on a tokenizer for word boundaries.</p>
  </div>
</div>

<!-- Question 25 -->
<div class="question" id="q25">
  <h3>Question 25</h3>
  <p>Which of the following best describes the relationship between entropy and perplexity in a language model?</p>
  <div class="options">
    <label><input type="radio" name="q25" value="d"> D. Entropy and perplexity are unrelated.</label><br>
    <label><input type="radio" name="q25" value="b"> B. Entropy is the square of perplexity.</label><br>
    <label><input type="radio" name="q25" value="a"> A. Perplexity is the inverse of entropy.</label><br>
    <label><input type="radio" name="q25" value="c"> C. Perplexity is the exponentiation of entropy.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q25', 'c')">Submit</button>
  <div class="context" id="context-q25">
    <p>Perplexity is calculated as 2 to the power of the entropy, measuring uncertainty in the prediction.</p>
  </div>
</div>

<!-- Question 26 -->
<div class="question" id="q26">
  <h3>Question 26</h3>
  <p>In a unigram language model, what is being calculated?</p>
  <div class="options">
    <label><input type="radio" name="q26" value="a"> A. P(word|previous_word)</label><br>
    <label><input type="radio" name="q26" value="d"> D. P(word1, word2)</label><br>
    <label><input type="radio" name="q26" value="b"> B. P(word)</label><br>
    <label><input type="radio" name="q26" value="c"> C. P(previous_word|word)</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q26', 'b')">Submit</button>
  <div class="context" id="context-q26">
    <p>In a unigram language model, we calculate P(word), which is the probability of a word occurring independently of any context.</p>
  </div>
</div>

<!-- Question 27 -->
<div class="question" id="q27">
  <h3>Question 27</h3>
  <p>Which temperature setting is likely to produce the most deterministic output in a sampling-based text generator?</p>
  <div class="options">
    <label><input type="radio" name="q27" value="d"> D. 2.0</label><br>
    <label><input type="radio" name="q27" value="a"> A. 0.2</label><br>
    <label><input type="radio" name="q27" value="b"> B. 0.5</label><br>
    <label><input type="radio" name="q27" value="c"> C. 1.0</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q27', 'a')">Submit</button>
  <div class="context" id="context-q27">
    <p>Lower temperatures produce more deterministic outputs by making high-probability words even more likely.</p>
  </div>
</div>

<!-- Question 28 -->
<div class="question" id="q28">
  <h3>Question 28</h3>
  <p>Why is a character-level RNN used for text generation tasks?</p>
  <div class="options">
    <label><input type="radio" name="q28" value="b"> B. It guarantees faster computation.</label><br>
    <label><input type="radio" name="q28" value="d"> D. It requires less training data.</label><br>
    <label><input type="radio" name="q28" value="a"> A. It eliminates the need for a tokenizer.</label><br>
    <label><input type="radio" name="q28" value="c"> C. It supports floating point arithmetic.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q28', 'a')">Submit</button>
  <div class="context" id="context-q28">
    <p>Character-level models can generate novel word sequences and donâ€™t rely on a tokenizer for word boundaries.</p>
  </div>
</div>

<!-- Question 29 -->
<div class="question" id="q29">
  <h3>Question 29</h3>
  <p>Why is a character-level RNN used for text generation tasks?</p>
  <div class="options">
    <label><input type="radio" name="q29" value="a"> A. It eliminates the need for a tokenizer.</label><br>
    <label><input type="radio" name="q29" value="d"> D. It requires less training data.</label><br>
    <label><input type="radio" name="q29" value="b"> B. It guarantees faster computation.</label><br>
    <label><input type="radio" name="q29" value="c"> C. It supports floating point arithmetic.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q29', 'a')">Submit</button>
  <div class="context" id="context-q29">
    <p>Character-level models can generate novel word sequences and donâ€™t rely on a tokenizer for word boundaries.</p>
  </div>
</div>

<!-- Question 30 -->
<div class="question" id="q30">
  <h3>Question 30</h3>
  <p>Why is a character-level RNN used for text generation tasks?</p>
  <div class="options">
    <label><input type="radio" name="q30" value="b"> B. It guarantees faster computation.</label><br>
    <label><input type="radio" name="q30" value="a"> A. It eliminates the need for a tokenizer.</label><br>
    <label><input type="radio" name="q30" value="d"> D. It requires less training data.</label><br>
    <label><input type="radio" name="q30" value="c"> C. It supports floating point arithmetic.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q30', 'a')">Submit</button>
  <div class="context" id="context-q30">
    <p>Character-level models can generate novel word sequences and donâ€™t rely on a tokenizer for word boundaries.</p>
  </div>
</div>

<!-- Question 31 -->
<div class="question" id="q31">
  <h3>Question 31</h3>
  <p>In a unigram language model, what is being calculated?</p>
  <div class="options">
    <label><input type="radio" name="q31" value="b"> B. P(word)</label><br>
    <label><input type="radio" name="q31" value="c"> C. P(previous_word|word)</label><br>
    <label><input type="radio" name="q31" value="a"> A. P(word|previous_word)</label><br>
    <label><input type="radio" name="q31" value="d"> D. P(word1, word2)</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q31', 'b')">Submit</button>
  <div class="context" id="context-q31">
    <p>In a unigram language model, we calculate P(word), which is the probability of a word occurring independently of any context.</p>
  </div>
</div>

<!-- Question 32 -->
<div class="question" id="q32">
  <h3>Question 32</h3>
  <p>In a unigram language model, what is being calculated?</p>
  <div class="options">
    <label><input type="radio" name="q32" value="a"> A. P(word|previous_word)</label><br>
    <label><input type="radio" name="q32" value="d"> D. P(word1, word2)</label><br>
    <label><input type="radio" name="q32" value="c"> C. P(previous_word|word)</label><br>
    <label><input type="radio" name="q32" value="b"> B. P(word)</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q32', 'b')">Submit</button>
  <div class="context" id="context-q32">
    <p>In a unigram language model, we calculate P(word), which is the probability of a word occurring independently of any context.</p>
  </div>
</div>

<!-- Question 33 -->
<div class="question" id="q33">
  <h3>Question 33</h3>
  <p>Why is a character-level RNN used for text generation tasks?</p>
  <div class="options">
    <label><input type="radio" name="q33" value="c"> C. It supports floating point arithmetic.</label><br>
    <label><input type="radio" name="q33" value="b"> B. It guarantees faster computation.</label><br>
    <label><input type="radio" name="q33" value="a"> A. It eliminates the need for a tokenizer.</label><br>
    <label><input type="radio" name="q33" value="d"> D. It requires less training data.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q33', 'a')">Submit</button>
  <div class="context" id="context-q33">
    <p>Character-level models can generate novel word sequences and donâ€™t rely on a tokenizer for word boundaries.</p>
  </div>
</div>

<!-- Question 34 -->
<div class="question" id="q34">
  <h3>Question 34</h3>
  <p>In a unigram language model, what is being calculated?</p>
  <div class="options">
    <label><input type="radio" name="q34" value="b"> B. P(word)</label><br>
    <label><input type="radio" name="q34" value="c"> C. P(previous_word|word)</label><br>
    <label><input type="radio" name="q34" value="d"> D. P(word1, word2)</label><br>
    <label><input type="radio" name="q34" value="a"> A. P(word|previous_word)</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q34', 'b')">Submit</button>
  <div class="context" id="context-q34">
    <p>In a unigram language model, we calculate P(word), which is the probability of a word occurring independently of any context.</p>
  </div>
</div>

<!-- Question 35 -->
<div class="question" id="q35">
  <h3>Question 35</h3>
  <p>Which of the following best describes the relationship between entropy and perplexity in a language model?</p>
  <div class="options">
    <label><input type="radio" name="q35" value="d"> D. Entropy and perplexity are unrelated.</label><br>
    <label><input type="radio" name="q35" value="b"> B. Entropy is the square of perplexity.</label><br>
    <label><input type="radio" name="q35" value="c"> C. Perplexity is the exponentiation of entropy.</label><br>
    <label><input type="radio" name="q35" value="a"> A. Perplexity is the inverse of entropy.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q35', 'c')">Submit</button>
  <div class="context" id="context-q35">
    <p>Perplexity is calculated as 2 to the power of the entropy, measuring uncertainty in the prediction.</p>
  </div>
</div>

<!-- Question 36 -->
<div class="question" id="q36">
  <h3>Question 36</h3>
  <p>Which of the following best describes the relationship between entropy and perplexity in a language model?</p>
  <div class="options">
    <label><input type="radio" name="q36" value="c"> C. Perplexity is the exponentiation of entropy.</label><br>
    <label><input type="radio" name="q36" value="b"> B. Entropy is the square of perplexity.</label><br>
    <label><input type="radio" name="q36" value="a"> A. Perplexity is the inverse of entropy.</label><br>
    <label><input type="radio" name="q36" value="d"> D. Entropy and perplexity are unrelated.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q36', 'c')">Submit</button>
  <div class="context" id="context-q36">
    <p>Perplexity is calculated as 2 to the power of the entropy, measuring uncertainty in the prediction.</p>
  </div>
</div>

<!-- Question 37 -->
<div class="question" id="q37">
  <h3>Question 37</h3>
  <p>In a unigram language model, what is being calculated?</p>
  <div class="options">
    <label><input type="radio" name="q37" value="d"> D. P(word1, word2)</label><br>
    <label><input type="radio" name="q37" value="c"> C. P(previous_word|word)</label><br>
    <label><input type="radio" name="q37" value="a"> A. P(word|previous_word)</label><br>
    <label><input type="radio" name="q37" value="b"> B. P(word)</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q37', 'b')">Submit</button>
  <div class="context" id="context-q37">
    <p>In a unigram language model, we calculate P(word), which is the probability of a word occurring independently of any context.</p>
  </div>
</div>

<!-- Question 38 -->
<div class="question" id="q38">
  <h3>Question 38</h3>
  <p>Which of the following best describes the relationship between entropy and perplexity in a language model?</p>
  <div class="options">
    <label><input type="radio" name="q38" value="a"> A. Perplexity is the inverse of entropy.</label><br>
    <label><input type="radio" name="q38" value="d"> D. Entropy and perplexity are unrelated.</label><br>
    <label><input type="radio" name="q38" value="c"> C. Perplexity is the exponentiation of entropy.</label><br>
    <label><input type="radio" name="q38" value="b"> B. Entropy is the square of perplexity.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q38', 'c')">Submit</button>
  <div class="context" id="context-q38">
    <p>Perplexity is calculated as 2 to the power of the entropy, measuring uncertainty in the prediction.</p>
  </div>
</div>

<!-- Question 39 -->
<div class="question" id="q39">
  <h3>Question 39</h3>
  <p>Why is a character-level RNN used for text generation tasks?</p>
  <div class="options">
    <label><input type="radio" name="q39" value="c"> C. It supports floating point arithmetic.</label><br>
    <label><input type="radio" name="q39" value="a"> A. It eliminates the need for a tokenizer.</label><br>
    <label><input type="radio" name="q39" value="b"> B. It guarantees faster computation.</label><br>
    <label><input type="radio" name="q39" value="d"> D. It requires less training data.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q39', 'a')">Submit</button>
  <div class="context" id="context-q39">
    <p>Character-level models can generate novel word sequences and donâ€™t rely on a tokenizer for word boundaries.</p>
  </div>
</div>

<!-- Question 40 -->
<div class="question" id="q40">
  <h3>Question 40</h3>
  <p>What does perplexity measure in the context of a language model?</p>
  <div class="options">
    <label><input type="radio" name="q40" value="d"> D. The vocabulary size used by the model.</label><br>
    <label><input type="radio" name="q40" value="c"> C. How well the model predicts a sequence of text.</label><br>
    <label><input type="radio" name="q40" value="a"> A. The length of the predicted sentence.</label><br>
    <label><input type="radio" name="q40" value="b"> B. The computational time needed for training.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q40', 'c')">Submit</button>
  <div class="context" id="context-q40">
    <p>Perplexity is a measure of how surprised a model is by the next word. A lower perplexity indicates better performance.</p>
  </div>
</div>

<!-- Question 41 -->
<div class="question" id="q41">
  <h3>Question 41</h3>
  <p>In a unigram language model, what is being calculated?</p>
  <div class="options">
    <label><input type="radio" name="q41" value="b"> B. P(word)</label><br>
    <label><input type="radio" name="q41" value="d"> D. P(word1, word2)</label><br>
    <label><input type="radio" name="q41" value="a"> A. P(word|previous_word)</label><br>
    <label><input type="radio" name="q41" value="c"> C. P(previous_word|word)</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q41', 'b')">Submit</button>
  <div class="context" id="context-q41">
    <p>In a unigram language model, we calculate P(word), which is the probability of a word occurring independently of any context.</p>
  </div>
</div>

<!-- Question 42 -->
<div class="question" id="q42">
  <h3>Question 42</h3>
  <p>In a unigram language model, what is being calculated?</p>
  <div class="options">
    <label><input type="radio" name="q42" value="a"> A. P(word|previous_word)</label><br>
    <label><input type="radio" name="q42" value="c"> C. P(previous_word|word)</label><br>
    <label><input type="radio" name="q42" value="d"> D. P(word1, word2)</label><br>
    <label><input type="radio" name="q42" value="b"> B. P(word)</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q42', 'b')">Submit</button>
  <div class="context" id="context-q42">
    <p>In a unigram language model, we calculate P(word), which is the probability of a word occurring independently of any context.</p>
  </div>
</div>

<!-- Question 43 -->
<div class="question" id="q43">
  <h3>Question 43</h3>
  <p>In a unigram language model, what is being calculated?</p>
  <div class="options">
    <label><input type="radio" name="q43" value="c"> C. P(previous_word|word)</label><br>
    <label><input type="radio" name="q43" value="a"> A. P(word|previous_word)</label><br>
    <label><input type="radio" name="q43" value="d"> D. P(word1, word2)</label><br>
    <label><input type="radio" name="q43" value="b"> B. P(word)</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q43', 'b')">Submit</button>
  <div class="context" id="context-q43">
    <p>In a unigram language model, we calculate P(word), which is the probability of a word occurring independently of any context.</p>
  </div>
</div>

<!-- Question 44 -->
<div class="question" id="q44">
  <h3>Question 44</h3>
  <p>Which temperature setting is likely to produce the most deterministic output in a sampling-based text generator?</p>
  <div class="options">
    <label><input type="radio" name="q44" value="d"> D. 2.0</label><br>
    <label><input type="radio" name="q44" value="a"> A. 0.2</label><br>
    <label><input type="radio" name="q44" value="b"> B. 0.5</label><br>
    <label><input type="radio" name="q44" value="c"> C. 1.0</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q44', 'a')">Submit</button>
  <div class="context" id="context-q44">
    <p>Lower temperatures produce more deterministic outputs by making high-probability words even more likely.</p>
  </div>
</div>

<!-- Question 45 -->
<div class="question" id="q45">
  <h3>Question 45</h3>
  <p>Why is a character-level RNN used for text generation tasks?</p>
  <div class="options">
    <label><input type="radio" name="q45" value="c"> C. It supports floating point arithmetic.</label><br>
    <label><input type="radio" name="q45" value="b"> B. It guarantees faster computation.</label><br>
    <label><input type="radio" name="q45" value="d"> D. It requires less training data.</label><br>
    <label><input type="radio" name="q45" value="a"> A. It eliminates the need for a tokenizer.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q45', 'a')">Submit</button>
  <div class="context" id="context-q45">
    <p>Character-level models can generate novel word sequences and donâ€™t rely on a tokenizer for word boundaries.</p>
  </div>
</div>

<!-- Question 46 -->
<div class="question" id="q46">
  <h3>Question 46</h3>
  <p>Which temperature setting is likely to produce the most deterministic output in a sampling-based text generator?</p>
  <div class="options">
    <label><input type="radio" name="q46" value="b"> B. 0.5</label><br>
    <label><input type="radio" name="q46" value="d"> D. 2.0</label><br>
    <label><input type="radio" name="q46" value="c"> C. 1.0</label><br>
    <label><input type="radio" name="q46" value="a"> A. 0.2</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q46', 'a')">Submit</button>
  <div class="context" id="context-q46">
    <p>Lower temperatures produce more deterministic outputs by making high-probability words even more likely.</p>
  </div>
</div>

<!-- Question 47 -->
<div class="question" id="q47">
  <h3>Question 47</h3>
  <p>Which of the following best describes the relationship between entropy and perplexity in a language model?</p>
  <div class="options">
    <label><input type="radio" name="q47" value="d"> D. Entropy and perplexity are unrelated.</label><br>
    <label><input type="radio" name="q47" value="c"> C. Perplexity is the exponentiation of entropy.</label><br>
    <label><input type="radio" name="q47" value="b"> B. Entropy is the square of perplexity.</label><br>
    <label><input type="radio" name="q47" value="a"> A. Perplexity is the inverse of entropy.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q47', 'c')">Submit</button>
  <div class="context" id="context-q47">
    <p>Perplexity is calculated as 2 to the power of the entropy, measuring uncertainty in the prediction.</p>
  </div>
</div>

<!-- Question 48 -->
<div class="question" id="q48">
  <h3>Question 48</h3>
  <p>Which of the following best describes the relationship between entropy and perplexity in a language model?</p>
  <div class="options">
    <label><input type="radio" name="q48" value="a"> A. Perplexity is the inverse of entropy.</label><br>
    <label><input type="radio" name="q48" value="b"> B. Entropy is the square of perplexity.</label><br>
    <label><input type="radio" name="q48" value="d"> D. Entropy and perplexity are unrelated.</label><br>
    <label><input type="radio" name="q48" value="c"> C. Perplexity is the exponentiation of entropy.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q48', 'c')">Submit</button>
  <div class="context" id="context-q48">
    <p>Perplexity is calculated as 2 to the power of the entropy, measuring uncertainty in the prediction.</p>
  </div>
</div>

<!-- Question 49 -->
<div class="question" id="q49">
  <h3>Question 49</h3>
  <p>What does perplexity measure in the context of a language model?</p>
  <div class="options">
    <label><input type="radio" name="q49" value="a"> A. The length of the predicted sentence.</label><br>
    <label><input type="radio" name="q49" value="b"> B. The computational time needed for training.</label><br>
    <label><input type="radio" name="q49" value="d"> D. The vocabulary size used by the model.</label><br>
    <label><input type="radio" name="q49" value="c"> C. How well the model predicts a sequence of text.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q49', 'c')">Submit</button>
  <div class="context" id="context-q49">
    <p>Perplexity is a measure of how surprised a model is by the next word. A lower perplexity indicates better performance.</p>
  </div>
</div>

<!-- Question 50 -->
<div class="question" id="q50">
  <h3>Question 50</h3>
  <p>What does perplexity measure in the context of a language model?</p>
  <div class="options">
    <label><input type="radio" name="q50" value="b"> B. The computational time needed for training.</label><br>
    <label><input type="radio" name="q50" value="a"> A. The length of the predicted sentence.</label><br>
    <label><input type="radio" name="q50" value="c"> C. How well the model predicts a sequence of text.</label><br>
    <label><input type="radio" name="q50" value="d"> D. The vocabulary size used by the model.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q50', 'c')">Submit</button>
  <div class="context" id="context-q50">
    <p>Perplexity is a measure of how surprised a model is by the next word. A lower perplexity indicates better performance.</p>
  </div>
</div>

<!-- Question 51 -->
<div class="question" id="q51">
  <h3>Question 51</h3>
  <p>What does perplexity measure in the context of a language model?</p>
  <div class="options">
    <label><input type="radio" name="q51" value="d"> D. The vocabulary size used by the model.</label><br>
    <label><input type="radio" name="q51" value="c"> C. How well the model predicts a sequence of text.</label><br>
    <label><input type="radio" name="q51" value="b"> B. The computational time needed for training.</label><br>
    <label><input type="radio" name="q51" value="a"> A. The length of the predicted sentence.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q51', 'c')">Submit</button>
  <div class="context" id="context-q51">
    <p>Perplexity is a measure of how surprised a model is by the next word. A lower perplexity indicates better performance.</p>
  </div>
</div>

<!-- Question 52 -->
<div class="question" id="q52">
  <h3>Question 52</h3>
  <p>Which temperature setting is likely to produce the most deterministic output in a sampling-based text generator?</p>
  <div class="options">
    <label><input type="radio" name="q52" value="b"> B. 0.5</label><br>
    <label><input type="radio" name="q52" value="d"> D. 2.0</label><br>
    <label><input type="radio" name="q52" value="a"> A. 0.2</label><br>
    <label><input type="radio" name="q52" value="c"> C. 1.0</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q52', 'a')">Submit</button>
  <div class="context" id="context-q52">
    <p>Lower temperatures produce more deterministic outputs by making high-probability words even more likely.</p>
  </div>
</div>

<!-- Question 53 -->
<div class="question" id="q53">
  <h3>Question 53</h3>
  <p>Why is a character-level RNN used for text generation tasks?</p>
  <div class="options">
    <label><input type="radio" name="q53" value="b"> B. It guarantees faster computation.</label><br>
    <label><input type="radio" name="q53" value="c"> C. It supports floating point arithmetic.</label><br>
    <label><input type="radio" name="q53" value="d"> D. It requires less training data.</label><br>
    <label><input type="radio" name="q53" value="a"> A. It eliminates the need for a tokenizer.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q53', 'a')">Submit</button>
  <div class="context" id="context-q53">
    <p>Character-level models can generate novel word sequences and donâ€™t rely on a tokenizer for word boundaries.</p>
  </div>
</div>

<!-- Question 54 -->
<div class="question" id="q54">
  <h3>Question 54</h3>
  <p>Why is a character-level RNN used for text generation tasks?</p>
  <div class="options">
    <label><input type="radio" name="q54" value="a"> A. It eliminates the need for a tokenizer.</label><br>
    <label><input type="radio" name="q54" value="c"> C. It supports floating point arithmetic.</label><br>
    <label><input type="radio" name="q54" value="b"> B. It guarantees faster computation.</label><br>
    <label><input type="radio" name="q54" value="d"> D. It requires less training data.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q54', 'a')">Submit</button>
  <div class="context" id="context-q54">
    <p>Character-level models can generate novel word sequences and donâ€™t rely on a tokenizer for word boundaries.</p>
  </div>
</div>

<!-- Question 55 -->
<div class="question" id="q55">
  <h3>Question 55</h3>
  <p>Which temperature setting is likely to produce the most deterministic output in a sampling-based text generator?</p>
  <div class="options">
    <label><input type="radio" name="q55" value="b"> B. 0.5</label><br>
    <label><input type="radio" name="q55" value="c"> C. 1.0</label><br>
    <label><input type="radio" name="q55" value="a"> A. 0.2</label><br>
    <label><input type="radio" name="q55" value="d"> D. 2.0</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q55', 'a')">Submit</button>
  <div class="context" id="context-q55">
    <p>Lower temperatures produce more deterministic outputs by making high-probability words even more likely.</p>
  </div>
</div>

<!-- Question 56 -->
<div class="question" id="q56">
  <h3>Question 56</h3>
  <p>Which temperature setting is likely to produce the most deterministic output in a sampling-based text generator?</p>
  <div class="options">
    <label><input type="radio" name="q56" value="b"> B. 0.5</label><br>
    <label><input type="radio" name="q56" value="d"> D. 2.0</label><br>
    <label><input type="radio" name="q56" value="a"> A. 0.2</label><br>
    <label><input type="radio" name="q56" value="c"> C. 1.0</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q56', 'a')">Submit</button>
  <div class="context" id="context-q56">
    <p>Lower temperatures produce more deterministic outputs by making high-probability words even more likely.</p>
  </div>
</div>

<!-- Question 57 -->
<div class="question" id="q57">
  <h3>Question 57</h3>
  <p>Why is a character-level RNN used for text generation tasks?</p>
  <div class="options">
    <label><input type="radio" name="q57" value="d"> D. It requires less training data.</label><br>
    <label><input type="radio" name="q57" value="b"> B. It guarantees faster computation.</label><br>
    <label><input type="radio" name="q57" value="a"> A. It eliminates the need for a tokenizer.</label><br>
    <label><input type="radio" name="q57" value="c"> C. It supports floating point arithmetic.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q57', 'a')">Submit</button>
  <div class="context" id="context-q57">
    <p>Character-level models can generate novel word sequences and donâ€™t rely on a tokenizer for word boundaries.</p>
  </div>
</div>

<!-- Question 58 -->
<div class="question" id="q58">
  <h3>Question 58</h3>
  <p>What does perplexity measure in the context of a language model?</p>
  <div class="options">
    <label><input type="radio" name="q58" value="b"> B. The computational time needed for training.</label><br>
    <label><input type="radio" name="q58" value="a"> A. The length of the predicted sentence.</label><br>
    <label><input type="radio" name="q58" value="d"> D. The vocabulary size used by the model.</label><br>
    <label><input type="radio" name="q58" value="c"> C. How well the model predicts a sequence of text.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q58', 'c')">Submit</button>
  <div class="context" id="context-q58">
    <p>Perplexity is a measure of how surprised a model is by the next word. A lower perplexity indicates better performance.</p>
  </div>
</div>

<!-- Question 59 -->
<div class="question" id="q59">
  <h3>Question 59</h3>
  <p>What does perplexity measure in the context of a language model?</p>
  <div class="options">
    <label><input type="radio" name="q59" value="a"> A. The length of the predicted sentence.</label><br>
    <label><input type="radio" name="q59" value="d"> D. The vocabulary size used by the model.</label><br>
    <label><input type="radio" name="q59" value="c"> C. How well the model predicts a sequence of text.</label><br>
    <label><input type="radio" name="q59" value="b"> B. The computational time needed for training.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q59', 'c')">Submit</button>
  <div class="context" id="context-q59">
    <p>Perplexity is a measure of how surprised a model is by the next word. A lower perplexity indicates better performance.</p>
  </div>
</div>

<!-- Question 60 -->
<div class="question" id="q60">
  <h3>Question 60</h3>
  <p>Which temperature setting is likely to produce the most deterministic output in a sampling-based text generator?</p>
  <div class="options">
    <label><input type="radio" name="q60" value="c"> C. 1.0</label><br>
    <label><input type="radio" name="q60" value="b"> B. 0.5</label><br>
    <label><input type="radio" name="q60" value="a"> A. 0.2</label><br>
    <label><input type="radio" name="q60" value="d"> D. 2.0</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q60', 'a')">Submit</button>
  <div class="context" id="context-q60">
    <p>Lower temperatures produce more deterministic outputs by making high-probability words even more likely.</p>
  </div>
</div>

<!-- Question 61 -->
<div class="question" id="q61">
  <h3>Question 61</h3>
  <p>Which of the following best describes the relationship between entropy and perplexity in a language model?</p>
  <div class="options">
    <label><input type="radio" name="q61" value="b"> B. Entropy is the square of perplexity.</label><br>
    <label><input type="radio" name="q61" value="c"> C. Perplexity is the exponentiation of entropy.</label><br>
    <label><input type="radio" name="q61" value="a"> A. Perplexity is the inverse of entropy.</label><br>
    <label><input type="radio" name="q61" value="d"> D. Entropy and perplexity are unrelated.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q61', 'c')">Submit</button>
  <div class="context" id="context-q61">
    <p>Perplexity is calculated as 2 to the power of the entropy, measuring uncertainty in the prediction.</p>
  </div>
</div>

<!-- Question 62 -->
<div class="question" id="q62">
  <h3>Question 62</h3>
  <p>Why is a character-level RNN used for text generation tasks?</p>
  <div class="options">
    <label><input type="radio" name="q62" value="b"> B. It guarantees faster computation.</label><br>
    <label><input type="radio" name="q62" value="c"> C. It supports floating point arithmetic.</label><br>
    <label><input type="radio" name="q62" value="d"> D. It requires less training data.</label><br>
    <label><input type="radio" name="q62" value="a"> A. It eliminates the need for a tokenizer.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q62', 'a')">Submit</button>
  <div class="context" id="context-q62">
    <p>Character-level models can generate novel word sequences and donâ€™t rely on a tokenizer for word boundaries.</p>
  </div>
</div>

<!-- Question 63 -->
<div class="question" id="q63">
  <h3>Question 63</h3>
  <p>Which of the following best describes the relationship between entropy and perplexity in a language model?</p>
  <div class="options">
    <label><input type="radio" name="q63" value="b"> B. Entropy is the square of perplexity.</label><br>
    <label><input type="radio" name="q63" value="d"> D. Entropy and perplexity are unrelated.</label><br>
    <label><input type="radio" name="q63" value="a"> A. Perplexity is the inverse of entropy.</label><br>
    <label><input type="radio" name="q63" value="c"> C. Perplexity is the exponentiation of entropy.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q63', 'c')">Submit</button>
  <div class="context" id="context-q63">
    <p>Perplexity is calculated as 2 to the power of the entropy, measuring uncertainty in the prediction.</p>
  </div>
</div>

<!-- Question 64 -->
<div class="question" id="q64">
  <h3>Question 64</h3>
  <p>Which temperature setting is likely to produce the most deterministic output in a sampling-based text generator?</p>
  <div class="options">
    <label><input type="radio" name="q64" value="a"> A. 0.2</label><br>
    <label><input type="radio" name="q64" value="b"> B. 0.5</label><br>
    <label><input type="radio" name="q64" value="d"> D. 2.0</label><br>
    <label><input type="radio" name="q64" value="c"> C. 1.0</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q64', 'a')">Submit</button>
  <div class="context" id="context-q64">
    <p>Lower temperatures produce more deterministic outputs by making high-probability words even more likely.</p>
  </div>
</div>

<!-- Question 65 -->
<div class="question" id="q65">
  <h3>Question 65</h3>
  <p>In a unigram language model, what is being calculated?</p>
  <div class="options">
    <label><input type="radio" name="q65" value="c"> C. P(previous_word|word)</label><br>
    <label><input type="radio" name="q65" value="d"> D. P(word1, word2)</label><br>
    <label><input type="radio" name="q65" value="b"> B. P(word)</label><br>
    <label><input type="radio" name="q65" value="a"> A. P(word|previous_word)</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q65', 'b')">Submit</button>
  <div class="context" id="context-q65">
    <p>In a unigram language model, we calculate P(word), which is the probability of a word occurring independently of any context.</p>
  </div>
</div>

<!-- Question 66 -->
<div class="question" id="q66">
  <h3>Question 66</h3>
  <p>Why is a character-level RNN used for text generation tasks?</p>
  <div class="options">
    <label><input type="radio" name="q66" value="c"> C. It supports floating point arithmetic.</label><br>
    <label><input type="radio" name="q66" value="a"> A. It eliminates the need for a tokenizer.</label><br>
    <label><input type="radio" name="q66" value="b"> B. It guarantees faster computation.</label><br>
    <label><input type="radio" name="q66" value="d"> D. It requires less training data.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q66', 'a')">Submit</button>
  <div class="context" id="context-q66">
    <p>Character-level models can generate novel word sequences and donâ€™t rely on a tokenizer for word boundaries.</p>
  </div>
</div>

<!-- Question 67 -->
<div class="question" id="q67">
  <h3>Question 67</h3>
  <p>Which temperature setting is likely to produce the most deterministic output in a sampling-based text generator?</p>
  <div class="options">
    <label><input type="radio" name="q67" value="a"> A. 0.2</label><br>
    <label><input type="radio" name="q67" value="d"> D. 2.0</label><br>
    <label><input type="radio" name="q67" value="c"> C. 1.0</label><br>
    <label><input type="radio" name="q67" value="b"> B. 0.5</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q67', 'a')">Submit</button>
  <div class="context" id="context-q67">
    <p>Lower temperatures produce more deterministic outputs by making high-probability words even more likely.</p>
  </div>
</div>

<!-- Question 68 -->
<div class="question" id="q68">
  <h3>Question 68</h3>
  <p>Which temperature setting is likely to produce the most deterministic output in a sampling-based text generator?</p>
  <div class="options">
    <label><input type="radio" name="q68" value="a"> A. 0.2</label><br>
    <label><input type="radio" name="q68" value="c"> C. 1.0</label><br>
    <label><input type="radio" name="q68" value="b"> B. 0.5</label><br>
    <label><input type="radio" name="q68" value="d"> D. 2.0</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q68', 'a')">Submit</button>
  <div class="context" id="context-q68">
    <p>Lower temperatures produce more deterministic outputs by making high-probability words even more likely.</p>
  </div>
</div>

<!-- Question 69 -->
<div class="question" id="q69">
  <h3>Question 69</h3>
  <p>In a unigram language model, what is being calculated?</p>
  <div class="options">
    <label><input type="radio" name="q69" value="a"> A. P(word|previous_word)</label><br>
    <label><input type="radio" name="q69" value="b"> B. P(word)</label><br>
    <label><input type="radio" name="q69" value="c"> C. P(previous_word|word)</label><br>
    <label><input type="radio" name="q69" value="d"> D. P(word1, word2)</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q69', 'b')">Submit</button>
  <div class="context" id="context-q69">
    <p>In a unigram language model, we calculate P(word), which is the probability of a word occurring independently of any context.</p>
  </div>
</div>

<!-- Question 70 -->
<div class="question" id="q70">
  <h3>Question 70</h3>
  <p>Which temperature setting is likely to produce the most deterministic output in a sampling-based text generator?</p>
  <div class="options">
    <label><input type="radio" name="q70" value="a"> A. 0.2</label><br>
    <label><input type="radio" name="q70" value="d"> D. 2.0</label><br>
    <label><input type="radio" name="q70" value="c"> C. 1.0</label><br>
    <label><input type="radio" name="q70" value="b"> B. 0.5</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q70', 'a')">Submit</button>
  <div class="context" id="context-q70">
    <p>Lower temperatures produce more deterministic outputs by making high-probability words even more likely.</p>
  </div>
</div>

<!-- Question 71 -->
<div class="question" id="q71">
  <h3>Question 71</h3>
  <p>What does perplexity measure in the context of a language model?</p>
  <div class="options">
    <label><input type="radio" name="q71" value="b"> B. The computational time needed for training.</label><br>
    <label><input type="radio" name="q71" value="a"> A. The length of the predicted sentence.</label><br>
    <label><input type="radio" name="q71" value="d"> D. The vocabulary size used by the model.</label><br>
    <label><input type="radio" name="q71" value="c"> C. How well the model predicts a sequence of text.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q71', 'c')">Submit</button>
  <div class="context" id="context-q71">
    <p>Perplexity is a measure of how surprised a model is by the next word. A lower perplexity indicates better performance.</p>
  </div>
</div>

<!-- Question 72 -->
<div class="question" id="q72">
  <h3>Question 72</h3>
  <p>Which of the following best describes the relationship between entropy and perplexity in a language model?</p>
  <div class="options">
    <label><input type="radio" name="q72" value="a"> A. Perplexity is the inverse of entropy.</label><br>
    <label><input type="radio" name="q72" value="c"> C. Perplexity is the exponentiation of entropy.</label><br>
    <label><input type="radio" name="q72" value="d"> D. Entropy and perplexity are unrelated.</label><br>
    <label><input type="radio" name="q72" value="b"> B. Entropy is the square of perplexity.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q72', 'c')">Submit</button>
  <div class="context" id="context-q72">
    <p>Perplexity is calculated as 2 to the power of the entropy, measuring uncertainty in the prediction.</p>
  </div>
</div>

<!-- Question 73 -->
<div class="question" id="q73">
  <h3>Question 73</h3>
  <p>What does perplexity measure in the context of a language model?</p>
  <div class="options">
    <label><input type="radio" name="q73" value="a"> A. The length of the predicted sentence.</label><br>
    <label><input type="radio" name="q73" value="d"> D. The vocabulary size used by the model.</label><br>
    <label><input type="radio" name="q73" value="c"> C. How well the model predicts a sequence of text.</label><br>
    <label><input type="radio" name="q73" value="b"> B. The computational time needed for training.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q73', 'c')">Submit</button>
  <div class="context" id="context-q73">
    <p>Perplexity is a measure of how surprised a model is by the next word. A lower perplexity indicates better performance.</p>
  </div>
</div>

<!-- Question 74 -->
<div class="question" id="q74">
  <h3>Question 74</h3>
  <p>What does perplexity measure in the context of a language model?</p>
  <div class="options">
    <label><input type="radio" name="q74" value="b"> B. The computational time needed for training.</label><br>
    <label><input type="radio" name="q74" value="d"> D. The vocabulary size used by the model.</label><br>
    <label><input type="radio" name="q74" value="c"> C. How well the model predicts a sequence of text.</label><br>
    <label><input type="radio" name="q74" value="a"> A. The length of the predicted sentence.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q74', 'c')">Submit</button>
  <div class="context" id="context-q74">
    <p>Perplexity is a measure of how surprised a model is by the next word. A lower perplexity indicates better performance.</p>
  </div>
</div>

<!-- Question 75 -->
<div class="question" id="q75">
  <h3>Question 75</h3>
  <p>Which temperature setting is likely to produce the most deterministic output in a sampling-based text generator?</p>
  <div class="options">
    <label><input type="radio" name="q75" value="b"> B. 0.5</label><br>
    <label><input type="radio" name="q75" value="a"> A. 0.2</label><br>
    <label><input type="radio" name="q75" value="c"> C. 1.0</label><br>
    <label><input type="radio" name="q75" value="d"> D. 2.0</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q75', 'a')">Submit</button>
  <div class="context" id="context-q75">
    <p>Lower temperatures produce more deterministic outputs by making high-probability words even more likely.</p>
  </div>
</div>

<!-- Question 76 -->
<div class="question" id="q76">
  <h3>Question 76</h3>
  <p>What does perplexity measure in the context of a language model?</p>
  <div class="options">
    <label><input type="radio" name="q76" value="c"> C. How well the model predicts a sequence of text.</label><br>
    <label><input type="radio" name="q76" value="d"> D. The vocabulary size used by the model.</label><br>
    <label><input type="radio" name="q76" value="a"> A. The length of the predicted sentence.</label><br>
    <label><input type="radio" name="q76" value="b"> B. The computational time needed for training.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q76', 'c')">Submit</button>
  <div class="context" id="context-q76">
    <p>Perplexity is a measure of how surprised a model is by the next word. A lower perplexity indicates better performance.</p>
  </div>
</div>

<!-- Question 77 -->
<div class="question" id="q77">
  <h3>Question 77</h3>
  <p>What does perplexity measure in the context of a language model?</p>
  <div class="options">
    <label><input type="radio" name="q77" value="c"> C. How well the model predicts a sequence of text.</label><br>
    <label><input type="radio" name="q77" value="b"> B. The computational time needed for training.</label><br>
    <label><input type="radio" name="q77" value="a"> A. The length of the predicted sentence.</label><br>
    <label><input type="radio" name="q77" value="d"> D. The vocabulary size used by the model.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q77', 'c')">Submit</button>
  <div class="context" id="context-q77">
    <p>Perplexity is a measure of how surprised a model is by the next word. A lower perplexity indicates better performance.</p>
  </div>
</div>

<!-- Question 78 -->
<div class="question" id="q78">
  <h3>Question 78</h3>
  <p>Which of the following best describes the relationship between entropy and perplexity in a language model?</p>
  <div class="options">
    <label><input type="radio" name="q78" value="b"> B. Entropy is the square of perplexity.</label><br>
    <label><input type="radio" name="q78" value="a"> A. Perplexity is the inverse of entropy.</label><br>
    <label><input type="radio" name="q78" value="d"> D. Entropy and perplexity are unrelated.</label><br>
    <label><input type="radio" name="q78" value="c"> C. Perplexity is the exponentiation of entropy.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q78', 'c')">Submit</button>
  <div class="context" id="context-q78">
    <p>Perplexity is calculated as 2 to the power of the entropy, measuring uncertainty in the prediction.</p>
  </div>
</div>

<!-- Question 79 -->
<div class="question" id="q79">
  <h3>Question 79</h3>
  <p>Which temperature setting is likely to produce the most deterministic output in a sampling-based text generator?</p>
  <div class="options">
    <label><input type="radio" name="q79" value="b"> B. 0.5</label><br>
    <label><input type="radio" name="q79" value="c"> C. 1.0</label><br>
    <label><input type="radio" name="q79" value="d"> D. 2.0</label><br>
    <label><input type="radio" name="q79" value="a"> A. 0.2</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q79', 'a')">Submit</button>
  <div class="context" id="context-q79">
    <p>Lower temperatures produce more deterministic outputs by making high-probability words even more likely.</p>
  </div>
</div>

<!-- Question 80 -->
<div class="question" id="q80">
  <h3>Question 80</h3>
  <p>Why is a character-level RNN used for text generation tasks?</p>
  <div class="options">
    <label><input type="radio" name="q80" value="b"> B. It guarantees faster computation.</label><br>
    <label><input type="radio" name="q80" value="d"> D. It requires less training data.</label><br>
    <label><input type="radio" name="q80" value="c"> C. It supports floating point arithmetic.</label><br>
    <label><input type="radio" name="q80" value="a"> A. It eliminates the need for a tokenizer.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q80', 'a')">Submit</button>
  <div class="context" id="context-q80">
    <p>Character-level models can generate novel word sequences and donâ€™t rely on a tokenizer for word boundaries.</p>
  </div>
</div>

<!-- Question 81 -->
<div class="question" id="q81">
  <h3>Question 81</h3>
  <p>Which of the following best describes the relationship between entropy and perplexity in a language model?</p>
  <div class="options">
    <label><input type="radio" name="q81" value="d"> D. Entropy and perplexity are unrelated.</label><br>
    <label><input type="radio" name="q81" value="b"> B. Entropy is the square of perplexity.</label><br>
    <label><input type="radio" name="q81" value="c"> C. Perplexity is the exponentiation of entropy.</label><br>
    <label><input type="radio" name="q81" value="a"> A. Perplexity is the inverse of entropy.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q81', 'c')">Submit</button>
  <div class="context" id="context-q81">
    <p>Perplexity is calculated as 2 to the power of the entropy, measuring uncertainty in the prediction.</p>
  </div>
</div>

<!-- Question 82 -->
<div class="question" id="q82">
  <h3>Question 82</h3>
  <p>In a unigram language model, what is being calculated?</p>
  <div class="options">
    <label><input type="radio" name="q82" value="c"> C. P(previous_word|word)</label><br>
    <label><input type="radio" name="q82" value="a"> A. P(word|previous_word)</label><br>
    <label><input type="radio" name="q82" value="b"> B. P(word)</label><br>
    <label><input type="radio" name="q82" value="d"> D. P(word1, word2)</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q82', 'b')">Submit</button>
  <div class="context" id="context-q82">
    <p>In a unigram language model, we calculate P(word), which is the probability of a word occurring independently of any context.</p>
  </div>
</div>

<!-- Question 83 -->
<div class="question" id="q83">
  <h3>Question 83</h3>
  <p>Which temperature setting is likely to produce the most deterministic output in a sampling-based text generator?</p>
  <div class="options">
    <label><input type="radio" name="q83" value="c"> C. 1.0</label><br>
    <label><input type="radio" name="q83" value="b"> B. 0.5</label><br>
    <label><input type="radio" name="q83" value="d"> D. 2.0</label><br>
    <label><input type="radio" name="q83" value="a"> A. 0.2</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q83', 'a')">Submit</button>
  <div class="context" id="context-q83">
    <p>Lower temperatures produce more deterministic outputs by making high-probability words even more likely.</p>
  </div>
</div>

<!-- Question 84 -->
<div class="question" id="q84">
  <h3>Question 84</h3>
  <p>Why is a character-level RNN used for text generation tasks?</p>
  <div class="options">
    <label><input type="radio" name="q84" value="a"> A. It eliminates the need for a tokenizer.</label><br>
    <label><input type="radio" name="q84" value="d"> D. It requires less training data.</label><br>
    <label><input type="radio" name="q84" value="b"> B. It guarantees faster computation.</label><br>
    <label><input type="radio" name="q84" value="c"> C. It supports floating point arithmetic.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q84', 'a')">Submit</button>
  <div class="context" id="context-q84">
    <p>Character-level models can generate novel word sequences and donâ€™t rely on a tokenizer for word boundaries.</p>
  </div>
</div>

<!-- Question 85 -->
<div class="question" id="q85">
  <h3>Question 85</h3>
  <p>Why is a character-level RNN used for text generation tasks?</p>
  <div class="options">
    <label><input type="radio" name="q85" value="a"> A. It eliminates the need for a tokenizer.</label><br>
    <label><input type="radio" name="q85" value="d"> D. It requires less training data.</label><br>
    <label><input type="radio" name="q85" value="b"> B. It guarantees faster computation.</label><br>
    <label><input type="radio" name="q85" value="c"> C. It supports floating point arithmetic.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q85', 'a')">Submit</button>
  <div class="context" id="context-q85">
    <p>Character-level models can generate novel word sequences and donâ€™t rely on a tokenizer for word boundaries.</p>
  </div>
</div>

<!-- Question 86 -->
<div class="question" id="q86">
  <h3>Question 86</h3>
  <p>What does perplexity measure in the context of a language model?</p>
  <div class="options">
    <label><input type="radio" name="q86" value="b"> B. The computational time needed for training.</label><br>
    <label><input type="radio" name="q86" value="c"> C. How well the model predicts a sequence of text.</label><br>
    <label><input type="radio" name="q86" value="a"> A. The length of the predicted sentence.</label><br>
    <label><input type="radio" name="q86" value="d"> D. The vocabulary size used by the model.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q86', 'c')">Submit</button>
  <div class="context" id="context-q86">
    <p>Perplexity is a measure of how surprised a model is by the next word. A lower perplexity indicates better performance.</p>
  </div>
</div>

<!-- Question 87 -->
<div class="question" id="q87">
  <h3>Question 87</h3>
  <p>In a unigram language model, what is being calculated?</p>
  <div class="options">
    <label><input type="radio" name="q87" value="a"> A. P(word|previous_word)</label><br>
    <label><input type="radio" name="q87" value="d"> D. P(word1, word2)</label><br>
    <label><input type="radio" name="q87" value="b"> B. P(word)</label><br>
    <label><input type="radio" name="q87" value="c"> C. P(previous_word|word)</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q87', 'b')">Submit</button>
  <div class="context" id="context-q87">
    <p>In a unigram language model, we calculate P(word), which is the probability of a word occurring independently of any context.</p>
  </div>
</div>

<!-- Question 88 -->
<div class="question" id="q88">
  <h3>Question 88</h3>
  <p>In a unigram language model, what is being calculated?</p>
  <div class="options">
    <label><input type="radio" name="q88" value="b"> B. P(word)</label><br>
    <label><input type="radio" name="q88" value="d"> D. P(word1, word2)</label><br>
    <label><input type="radio" name="q88" value="c"> C. P(previous_word|word)</label><br>
    <label><input type="radio" name="q88" value="a"> A. P(word|previous_word)</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q88', 'b')">Submit</button>
  <div class="context" id="context-q88">
    <p>In a unigram language model, we calculate P(word), which is the probability of a word occurring independently of any context.</p>
  </div>
</div>

<!-- Question 89 -->
<div class="question" id="q89">
  <h3>Question 89</h3>
  <p>Why is a character-level RNN used for text generation tasks?</p>
  <div class="options">
    <label><input type="radio" name="q89" value="b"> B. It guarantees faster computation.</label><br>
    <label><input type="radio" name="q89" value="c"> C. It supports floating point arithmetic.</label><br>
    <label><input type="radio" name="q89" value="a"> A. It eliminates the need for a tokenizer.</label><br>
    <label><input type="radio" name="q89" value="d"> D. It requires less training data.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q89', 'a')">Submit</button>
  <div class="context" id="context-q89">
    <p>Character-level models can generate novel word sequences and donâ€™t rely on a tokenizer for word boundaries.</p>
  </div>
</div>

<!-- Question 90 -->
<div class="question" id="q90">
  <h3>Question 90</h3>
  <p>What does perplexity measure in the context of a language model?</p>
  <div class="options">
    <label><input type="radio" name="q90" value="b"> B. The computational time needed for training.</label><br>
    <label><input type="radio" name="q90" value="a"> A. The length of the predicted sentence.</label><br>
    <label><input type="radio" name="q90" value="c"> C. How well the model predicts a sequence of text.</label><br>
    <label><input type="radio" name="q90" value="d"> D. The vocabulary size used by the model.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q90', 'c')">Submit</button>
  <div class="context" id="context-q90">
    <p>Perplexity is a measure of how surprised a model is by the next word. A lower perplexity indicates better performance.</p>
  </div>
</div>

<!-- Question 91 -->
<div class="question" id="q91">
  <h3>Question 91</h3>
  <p>In a unigram language model, what is being calculated?</p>
  <div class="options">
    <label><input type="radio" name="q91" value="a"> A. P(word|previous_word)</label><br>
    <label><input type="radio" name="q91" value="c"> C. P(previous_word|word)</label><br>
    <label><input type="radio" name="q91" value="d"> D. P(word1, word2)</label><br>
    <label><input type="radio" name="q91" value="b"> B. P(word)</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q91', 'b')">Submit</button>
  <div class="context" id="context-q91">
    <p>In a unigram language model, we calculate P(word), which is the probability of a word occurring independently of any context.</p>
  </div>
</div>

<!-- Question 92 -->
<div class="question" id="q92">
  <h3>Question 92</h3>
  <p>Which temperature setting is likely to produce the most deterministic output in a sampling-based text generator?</p>
  <div class="options">
    <label><input type="radio" name="q92" value="b"> B. 0.5</label><br>
    <label><input type="radio" name="q92" value="a"> A. 0.2</label><br>
    <label><input type="radio" name="q92" value="c"> C. 1.0</label><br>
    <label><input type="radio" name="q92" value="d"> D. 2.0</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q92', 'a')">Submit</button>
  <div class="context" id="context-q92">
    <p>Lower temperatures produce more deterministic outputs by making high-probability words even more likely.</p>
  </div>
</div>

<!-- Question 93 -->
<div class="question" id="q93">
  <h3>Question 93</h3>
  <p>What does perplexity measure in the context of a language model?</p>
  <div class="options">
    <label><input type="radio" name="q93" value="b"> B. The computational time needed for training.</label><br>
    <label><input type="radio" name="q93" value="a"> A. The length of the predicted sentence.</label><br>
    <label><input type="radio" name="q93" value="d"> D. The vocabulary size used by the model.</label><br>
    <label><input type="radio" name="q93" value="c"> C. How well the model predicts a sequence of text.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q93', 'c')">Submit</button>
  <div class="context" id="context-q93">
    <p>Perplexity is a measure of how surprised a model is by the next word. A lower perplexity indicates better performance.</p>
  </div>
</div>

<!-- Question 94 -->
<div class="question" id="q94">
  <h3>Question 94</h3>
  <p>Why is a character-level RNN used for text generation tasks?</p>
  <div class="options">
    <label><input type="radio" name="q94" value="b"> B. It guarantees faster computation.</label><br>
    <label><input type="radio" name="q94" value="d"> D. It requires less training data.</label><br>
    <label><input type="radio" name="q94" value="a"> A. It eliminates the need for a tokenizer.</label><br>
    <label><input type="radio" name="q94" value="c"> C. It supports floating point arithmetic.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q94', 'a')">Submit</button>
  <div class="context" id="context-q94">
    <p>Character-level models can generate novel word sequences and donâ€™t rely on a tokenizer for word boundaries.</p>
  </div>
</div>

<!-- Question 95 -->
<div class="question" id="q95">
  <h3>Question 95</h3>
  <p>What does perplexity measure in the context of a language model?</p>
  <div class="options">
    <label><input type="radio" name="q95" value="a"> A. The length of the predicted sentence.</label><br>
    <label><input type="radio" name="q95" value="b"> B. The computational time needed for training.</label><br>
    <label><input type="radio" name="q95" value="c"> C. How well the model predicts a sequence of text.</label><br>
    <label><input type="radio" name="q95" value="d"> D. The vocabulary size used by the model.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q95', 'c')">Submit</button>
  <div class="context" id="context-q95">
    <p>Perplexity is a measure of how surprised a model is by the next word. A lower perplexity indicates better performance.</p>
  </div>
</div>

<!-- Question 96 -->
<div class="question" id="q96">
  <h3>Question 96</h3>
  <p>Which temperature setting is likely to produce the most deterministic output in a sampling-based text generator?</p>
  <div class="options">
    <label><input type="radio" name="q96" value="a"> A. 0.2</label><br>
    <label><input type="radio" name="q96" value="b"> B. 0.5</label><br>
    <label><input type="radio" name="q96" value="c"> C. 1.0</label><br>
    <label><input type="radio" name="q96" value="d"> D. 2.0</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q96', 'a')">Submit</button>
  <div class="context" id="context-q96">
    <p>Lower temperatures produce more deterministic outputs by making high-probability words even more likely.</p>
  </div>
</div>

<!-- Question 97 -->
<div class="question" id="q97">
  <h3>Question 97</h3>
  <p>In a unigram language model, what is being calculated?</p>
  <div class="options">
    <label><input type="radio" name="q97" value="c"> C. P(previous_word|word)</label><br>
    <label><input type="radio" name="q97" value="a"> A. P(word|previous_word)</label><br>
    <label><input type="radio" name="q97" value="d"> D. P(word1, word2)</label><br>
    <label><input type="radio" name="q97" value="b"> B. P(word)</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q97', 'b')">Submit</button>
  <div class="context" id="context-q97">
    <p>In a unigram language model, we calculate P(word), which is the probability of a word occurring independently of any context.</p>
  </div>
</div>

<!-- Question 98 -->
<div class="question" id="q98">
  <h3>Question 98</h3>
  <p>What does perplexity measure in the context of a language model?</p>
  <div class="options">
    <label><input type="radio" name="q98" value="b"> B. The computational time needed for training.</label><br>
    <label><input type="radio" name="q98" value="d"> D. The vocabulary size used by the model.</label><br>
    <label><input type="radio" name="q98" value="c"> C. How well the model predicts a sequence of text.</label><br>
    <label><input type="radio" name="q98" value="a"> A. The length of the predicted sentence.</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q98', 'c')">Submit</button>
  <div class="context" id="context-q98">
    <p>Perplexity is a measure of how surprised a model is by the next word. A lower perplexity indicates better performance.</p>
  </div>
</div>

<!-- Question 99 -->
<div class="question" id="q99">
  <h3>Question 99</h3>
  <p>In a unigram language model, what is being calculated?</p>
  <div class="options">
    <label><input type="radio" name="q99" value="d"> D. P(word1, word2)</label><br>
    <label><input type="radio" name="q99" value="c"> C. P(previous_word|word)</label><br>
    <label><input type="radio" name="q99" value="b"> B. P(word)</label><br>
    <label><input type="radio" name="q99" value="a"> A. P(word|previous_word)</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q99', 'b')">Submit</button>
  <div class="context" id="context-q99">
    <p>In a unigram language model, we calculate P(word), which is the probability of a word occurring independently of any context.</p>
  </div>
</div>

<!-- Question 100 -->
<div class="question" id="q100">
  <h3>Question 100</h3>
  <p>In a unigram language model, what is being calculated?</p>
  <div class="options">
    <label><input type="radio" name="q100" value="c"> C. P(previous_word|word)</label><br>
    <label><input type="radio" name="q100" value="b"> B. P(word)</label><br>
    <label><input type="radio" name="q100" value="d"> D. P(word1, word2)</label><br>
    <label><input type="radio" name="q100" value="a"> A. P(word|previous_word)</label><br>
  </div>
  <button class="submit-btn" onclick="checkAnswer('q100', 'b')">Submit</button>
  <div class="context" id="context-q100">
    <p>In a unigram language model, we calculate P(word), which is the probability of a word occurring independently of any context.</p>
  </div>
</div>

</body>
</html>
